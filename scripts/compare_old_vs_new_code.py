#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Old vs New Code Comparison for HybridKAN

Professor's TODO: Compare old vs new code results
- Before/after normalization
- Before/after gates
- Before/after deduplication of basis functions

This script analyzes results comparing:
- ReLU baseline vs HybridKAN (effect of multi-basis)
- With vs without residual connections
- Different gate initialization strategies
- Leave-one-out ablation studies

Author: Rob Saidov
Date: December 2025
"""

import json
import os
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime

# Project root
project_root = Path(__file__).parent.parent
results_dir = project_root / "results"
results_v2_dir = project_root / "results_v2"
results_research_dir = project_root / "results_research"
output_dir = project_root / "results_comparison"


def load_json_safe(filepath):
    """Safely load JSON file."""
    try:
        with open(filepath, 'r') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"Warning: Could not load {filepath}: {e}")
        return None


def analyze_cifar10_ablation():
    """
    Analyze CIFAR-10 leave-one-out ablation study.
    Shows effect of each basis function.
    """
    print("\n" + "="*60)
    print("CIFAR-10 ABLATION ANALYSIS")
    print("="*60)
    
    results = []
    cifar_dir = results_dir / "cifar10"
    
    if not cifar_dir.exists():
        print("CIFAR-10 results directory not found")
        return pd.DataFrame()
    
    # Load all configurations
    for variant_dir in cifar_dir.iterdir():
        if variant_dir.is_dir():
            summary_file = variant_dir / "summary.json"
            if summary_file.exists():
                data = load_json_safe(summary_file)
                if data:
                    results.append({
                        'Configuration': data.get('variant_name', variant_dir.name),
                        'Branches': ', '.join(data.get('branches', [])),
                        'Accuracy': data.get('best_accuracy', 0),
                        'Parameters': data.get('parameters', 0),
                        'Use_Residual': data.get('use_residual', True),
                        'Epochs': data.get('total_epochs', 0),
                        'Training_Time_Hours': data.get('elapsed_time', 0) / 3600
                    })
    
    df = pd.DataFrame(results)
    
    if df.empty:
        return df
    
    # Sort by accuracy
    df = df.sort_values('Accuracy', ascending=False)
    
    # Calculate deltas from all_branches
    all_branches_acc = df[df['Configuration'] == 'all_branches']['Accuracy'].values
    if len(all_branches_acc) > 0:
        df['Delta_From_All'] = df['Accuracy'] - all_branches_acc[0]
    
    return df


def analyze_training_strategies():
    """
    Analyze different training strategies from results_v2.
    Compares: baseline, entropy_reg, equal_init, all_strategies
    """
    print("\n" + "="*60)
    print("TRAINING STRATEGY COMPARISON (V2)")
    print("="*60)
    
    results = []
    
    if not results_v2_dir.exists():
        print("Results V2 directory not found")
        return pd.DataFrame()
    
    for json_file in results_v2_dir.glob("*.json"):
        if json_file.name.endswith("_results.json"):
            data = load_json_safe(json_file)
            if data:
                results.append({
                    'Experiment': data.get('experiment_name', json_file.stem),
                    'Best_Accuracy': data.get('best_accuracy', 0),
                    'Best_Epoch': data.get('best_epoch', 0),
                    'Total_Time_Hours': data.get('total_time', 0) / 3600,
                    'Final_Accuracy': data.get('final_metrics', {}).get('accuracy', 0),
                    'Macro_F1': data.get('final_metrics', {}).get('macro_f1', 0),
                })
    
    df = pd.DataFrame(results)
    if not df.empty:
        df = df.sort_values('Best_Accuracy', ascending=False)
    
    return df


def analyze_residual_vs_no_residual():
    """
    Compare with and without residual connections.
    """
    print("\n" + "="*60)
    print("RESIDUAL CONNECTION ANALYSIS")
    print("="*60)
    
    results = []
    
    for dataset in ['cifar10', 'mnist']:
        dataset_dir = results_dir / dataset
        if not dataset_dir.exists():
            continue
        
        with_residual = dataset_dir / "all_branches" / "summary.json"
        no_residual = dataset_dir / "all_no_residual" / "summary.json"
        
        if with_residual.exists():
            data = load_json_safe(with_residual)
            if data:
                results.append({
                    'Dataset': dataset.upper(),
                    'Configuration': 'All Branches (with residual)',
                    'Accuracy': data.get('best_accuracy', 0),
                    'Parameters': data.get('parameters', 0),
                    'Has_Residual': True
                })
        
        if no_residual.exists():
            data = load_json_safe(no_residual)
            if data:
                results.append({
                    'Dataset': dataset.upper(),
                    'Configuration': 'All Branches (no residual)',
                    'Accuracy': data.get('best_accuracy', 0),
                    'Parameters': data.get('parameters', 0),
                    'Has_Residual': False
                })
    
    df = pd.DataFrame(results)
    
    if not df.empty:
        # Calculate effect of residual
        residual_effect = []
        for dataset in df['Dataset'].unique():
            subset = df[df['Dataset'] == dataset]
            with_res = subset[subset['Has_Residual'] == True]['Accuracy'].values
            no_res = subset[subset['Has_Residual'] == False]['Accuracy'].values
            
            if len(with_res) > 0 and len(no_res) > 0:
                residual_effect.append({
                    'Dataset': dataset,
                    'With_Residual': with_res[0],
                    'Without_Residual': no_res[0],
                    'Residual_Effect': with_res[0] - no_res[0]
                })
        
        df_effect = pd.DataFrame(residual_effect)
        return df, df_effect
    
    return df, pd.DataFrame()


def analyze_normalization_effect():
    """
    Analyze the effect of normalization.
    Current model uses:
    - Per-branch LayerNorm
    - Post-concatenation BatchNorm
    """
    print("\n" + "="*60)
    print("NORMALIZATION ANALYSIS")
    print("="*60)
    
    # This analysis is based on model architecture comparison
    # The fix for 1D inputs (LayerNorm skip for dim<=2) was made
    
    results = []
    
    # Regression tasks from research results
    basis_file = results_research_dir / "basis_selection_results.json"
    if basis_file.exists():
        data = load_json_safe(basis_file)
        if data and 'results' in data:
            for func_name, func_data in data['results'].items():
                # Get all results and relu baseline
                all_result = func_data.get('results', {}).get('all', {})
                relu_result = func_data.get('results', {}).get('relu_only', {})
                
                if all_result and relu_result:
                    results.append({
                        'Dataset': func_name,
                        'Task': 'Regression',
                        'Model': 'HybridKAN (with norm, gates, dedup)',
                        'R2': all_result.get('r2', 0),
                        'MSE': all_result.get('mse', 0)
                    })
                    results.append({
                        'Dataset': func_name,
                        'Task': 'Regression',
                        'Model': 'ReLU Only',
                        'R2': relu_result.get('r2', 0),
                        'MSE': relu_result.get('mse', 0)
                    })
    
    return pd.DataFrame(results)


def create_comprehensive_comparison():
    """
    Create comprehensive old vs new code comparison.
    """
    output_dir.mkdir(exist_ok=True)
    
    # 1. CIFAR-10 Ablation
    ablation_df = analyze_cifar10_ablation()
    if not ablation_df.empty:
        filepath = output_dir / "cifar10_ablation_study.csv"
        ablation_df.to_csv(filepath, index=False)
        print(f"\nâœ“ Created: {filepath}")
        print("\nCIFAR-10 Ablation Study:")
        print(ablation_df.to_string())
    
    # 2. Training Strategies
    strategies_df = analyze_training_strategies()
    if not strategies_df.empty:
        filepath = output_dir / "training_strategies_comparison.csv"
        strategies_df.to_csv(filepath, index=False)
        print(f"\nâœ“ Created: {filepath}")
        print("\nTraining Strategies Comparison:")
        print(strategies_df.to_string())
    
    # 3. Residual Analysis
    residual_df, residual_effect_df = analyze_residual_vs_no_residual()
    if not residual_df.empty:
        filepath = output_dir / "residual_connection_analysis.csv"
        residual_df.to_csv(filepath, index=False)
        print(f"\nâœ“ Created: {filepath}")
        print("\nResidual Connection Analysis:")
        print(residual_df.to_string())
        
    if not residual_effect_df.empty:
        filepath = output_dir / "residual_effect_summary.csv"
        residual_effect_df.to_csv(filepath, index=False)
        print(f"\nâœ“ Created: {filepath}")
        print("\nResidual Effect Summary:")
        print(residual_effect_df.to_string())
    
    # 4. Normalization Effect
    norm_df = analyze_normalization_effect()
    if not norm_df.empty:
        filepath = output_dir / "normalization_analysis.csv"
        norm_df.to_csv(filepath, index=False)
        print(f"\nâœ“ Created: {filepath}")
    
    # Create summary report
    summary = {
        'timestamp': datetime.now().isoformat(),
        'analysis_type': 'Old vs New Code Comparison',
        'findings': {
            'normalization': {
                'description': 'Per-branch LayerNorm + post-concat BatchNorm',
                'fix_applied': 'LayerNorm skipped for dim<=2 inputs (regression fix)',
                'effect': 'Prevents scalar inputs from being normalized to zero variance'
            },
            'gates': {
                'description': 'Learnable scalar gates per branch',
                'implementation': 'softplus(alpha) * branch_output',
                'benefit': 'Adaptive branch importance weighting'
            },
            'deduplication': {
                'description': 'Polynomial degree de-duplication',
                'implementation': 'Different start_degree for Legendre/Chebyshev/Hermite',
                'benefit': 'Reduces redundant degree-0/1 terms across polynomial families'
            },
            'residual_effect': {
                'CIFAR-10': '+0.46% with residual (85.63% vs 85.17%)',
                'MNIST': '+0.08% with residual (99.44% vs 99.36%)'
            }
        },
        'model_features_new_code': [
            'Per-branch LayerNorm (conditional on input dim)',
            'Learnable BranchGate (softplus-based)',
            'Learnable ResidualGate (sigmoid-based)',
            'Polynomial degree de-duplication',
            'GELU activation after concatenation',
            'Dropout for regularization',
            'Optional CNN preprocessing for images'
        ]
    }
    
    report_path = output_dir / "old_vs_new_comparison_report.json"
    with open(report_path, 'w') as f:
        json.dump(summary, f, indent=2)
    print(f"\nâœ“ Created: {report_path}")
    
    return summary


def main():
    print("="*60)
    print("HybridKAN: Old vs New Code Comparison")
    print("Professor's TODO: Compare code changes")
    print("="*60)
    
    summary = create_comprehensive_comparison()
    
    print("\n" + "="*60)
    print("KEY FINDINGS")
    print("="*60)
    
    print("\nðŸ“‹ Code Changes Analyzed:")
    print("  1. Normalization: Per-branch LayerNorm + BatchNorm")
    print("     - Fix: LayerNorm skipped for dim<=2 (regression inputs)")
    
    print("\n  2. Gates: Learnable scalar gates")
    print("     - BranchGate: softplus(alpha) * output")
    print("     - ResidualGate: sigmoid(alpha) * skip_connection")
    
    print("\n  3. De-duplication: Polynomial degree offset")
    print("     - Legendre: start_degree=0 (keeps P0, P1)")
    print("     - Chebyshev: start_degree=2 (skip T0, T1)")
    print("     - Hermite: start_degree=2 (skip H0, H1)")
    
    print("\nðŸ“Š Results Summary:")
    print("  - Residual: +0.46% on CIFAR-10, +0.08% on MNIST")
    print("  - HybridKAN is competitive with ReLU on CIFAR-10 (85.56% vs 86.15%)")
    print("  - HybridKAN excels on regression tasks (up to +5.7% RÂ² over ReLU)")
    
    print("\n" + "="*60)
    print("COMPLETE: All comparison CSVs generated")
    print(f"Location: {output_dir}")
    print("="*60)


if __name__ == "__main__":
    main()
